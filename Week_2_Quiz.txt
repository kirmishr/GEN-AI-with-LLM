1.
Question 1
 Fill in the blanks: __________ involves using many prompt-completion examples as the labeled training dataset to continue training the model by updating its weights.  This is different from _________ where you provide prompt-completion examples during inference.



Prompt engineering, Pre-training



Pre-training, Instruction fine-tuning



INSTRUCTION FINE-TUNING, IN-CONTEXT LEARNING



In-context learning, Instruction fine-tuning 


2.
Question 2
Fine-tuning a model on a single task can improve model performance specifically on that task; however, it can also degrade the performance of other tasks as a side effect.  This phenomenon is known as: 



Model toxicity



Catastrophic loss



Instruction bias



CATASTROPHIC FORGETTING


3.
Question 3
Which evaluation metric below focuses on precision in matching generated output to the reference text and is used for text translation?



ROUGE-2



ROUGE-1



BLEU



HELM


4.
Question 4
Which of the following statements about multi-task finetuning is correct? Select all that apply:



MULTI-TASK FINETUNING CAN HELP PREVENT CATASTROPHIC FORGETTING.



Multi-task finetuning requires separate models for each task being performed.



FLAN-T5 WAS TRAINED WITH MULTI-TASK FINETUNING.



Performing multi-task finetuning may lead to slower inference.


5.
Question 5
"Smaller LLMs can struggle with one-shot and few-shot inference:"

Is this true or false?



TRUE



False


6.
Question 6
Which of the following are Parameter Efficient Fine-Tuning (PEFT) methods? Select all that apply.



REPARAMETERIZATION



ADDITIVE



SELECTIVE



Subtractive


7.
Question 7
Which of the following best describes how LoRA works?



LoRA trains  a smaller, distilled version of the pre-trained LLM to reduce model size



LoRA freezes all weights in the original model layers and introduces new components which are trained on new data.



LORA DECOMPOSES WEIGHTS INTO TWO SMALLER RANK MATRICES AND TRAINS THOSE INSTEAD OF THE FULL MODEL WEIGHTS.



LoRA continues the original pre-training objective on new data to update the weights of the original model.


8.
Question 8
What is a soft prompt in the context of LLMs (Large Language Models)?



A SET OF TRAINABLE TOKENS THAT ARE ADDED TO A PROMPT AND WHOSE VALUES ARE UPDATED DURING ADDITIONAL TRAINING TO IMPROVE PERFORMANCE ON SPECIFIC TASKS.



A strict and explicit input text that serves as a starting point for the model's generation.



A technique to limit the creativity of the model and enforce specific output patterns.



A method to control the model's behavior by adjusting the learning rate during training.


9.
Question 9
"Prompt Tuning is a technique used to adjust all hyperparameters of a language model."

Is this true or false?



True



FALSE


10.
Question 10
"PEFT methods can reduce the memory needed for fine-tuning dramatically, sometimes to just 12-20% of the memory needed for full fine-tuning."

Is this true or false?



TRUE



False